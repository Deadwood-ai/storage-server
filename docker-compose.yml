services:
  deadwood-api:
    image: ghcr.io/deadwood-ai/deadwood-api:latest
    restart: always
    deploy:
      resources:
        limits:
          cpus: '4.5'
          memory: 5G
        reservations:
          cpus: '1'
          memory: 1G
    ports:
      - 127.0.0.1:40040:40040
    environment:
      # this is the location INSIDE the container, only change when the mountpoint changes
      BASE_DIR: /data

      # adjust the settings of the HOST folders here
      ARCHIVE_DIR: archive
      COG_DIR: cogs    

      # setup the uvicorn server here
      UVICORN_PORT: 40040
      UVICORN_HOST: 0.0.0.0
      UVICORN_ROOT_PATH: /api/v1

      # Supabase settings 
      SUPABASE_URL: ${SUPABASE_URL}
      SUPABASE_KEY: ${SUPABASE_KEY}
      PROCESSOR_USERNAME: processor@deadtrees.earth
      PROCESSOR_PASSWORD: ${PROCESSOR_PASSWORD}

      # set the tables for the data
      DATASETS_TABLE: v1_datasets
      METADATA_TABLE: v1_metadata
      COGS_TABLE: v1_cogs
      LABELS_TABLE: v1_labels

      # queue settings
      QUEUE_TABLE: v1_queue
      QUEUE_POSITION_TABLE: v1_queue_positions
      CONCURRENT_TASKS: 2
      TASK_RETRY_DELAY: 60
      
    volumes:
      - ./production:/data
    
    command: python run.py server

  # add the mirgration server
  migrate:
    image: ghcr.io/deadwood-ai/deadwood-api:latest
    links:
      - deadwood-api
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 2G
    environment:
      BASE_DIR: /data
      ARCHIVE_DIR: archive
      COG_DIR: cogs
      SUPABASE_KEY: ${SUPABASE_KEY}
      SUPABASE_URL: ${SUPABASE_URL}
      PROCESSOR_USERNAME: processor@deadtrees.earth
      PROCESSOR_PASSWORD: ${PROCESSOR_PASSWORD}
      OLD_ARCHIVE_PATH: /data/archive
      API_URL: http://deadwood-api:40040
      MIGRATION_TABLE: migrate_v1
      DATASETS_TABLE: v1_datasets
      METADATA_TABLE: v1_metadata
      COGS_TABLE: v1_cogs
      LABELS_TABLE: v1_labels
      QUEUE_TABLE: v1_queue
      QUEUE_POSITION_TABLE: v1_queue_positions
      CONCURRENT_TASKS: 2
      TASK_RETRY_DELAY: 60
    volumes:
      - ./production:/data
    command: echo "Use migration service like 'docker compose --rm migrate bash'"

  # create a python container for direct access of the backend
  jupyter:
    build:
      context: ./jupyter
      dockerfile: Dockerfile
    restart: unless-stopped
    ports:
      - 127.0.0.1:8888:8888
    environment:
      JUPYTER_TOKEN: ${JUPYTER_TOKEN}
      SUPABASE_URL: ${SUPABASE_URL}
      SUPABASE_KEY: ${SUPABASE_KEY}
      METADATA_TABLE: upload_files_dev
      PROCESSOR_PASSWORD: ${PROCESSOR_PASSWORD}
    volumes:
      - ./production:/data
      - type: bind
        source: /home/mirko/.ssh/id_rsa
        target: /root/.ssh/id_rsa
      - type: bind
        source: /home/mirko/.ssh/id_rsa.pub
        target: /root/.ssh/id_rsa.pub
    command: jupyter notebook --NotebookApp.ip=0.0.0.0 --allow-root --no-browser --NotebookApp.port=8888

  # create a prometheus container for monitoring
  prometheus:
    image: prom/prometheus
    restart: unless-stopped
    user: root
    volumes:
      - ./production/prometheus:/prometheus
      - type: bind
        source: ./prometheus/prometheus.yml
        target: /etc/prometheus/prometheus.yml
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
#      - '--web.console.libraries=/etc/prometheus/console_libraries'
#      - '--web.console.templates=/etc/prometheus/consoles'
#      - '--web.enable-lifecycle'
    ports:
      - "9090:9090"
